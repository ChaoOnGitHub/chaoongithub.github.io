<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="NLP,Python,快速指南," />










<meta name="description" content="1. NLP简介  标记化  把文本转化为标记的过程 标记    文本中出现的实体或词汇 文本对象 句子/短语/词汇/文章  2. 文本处理   移除噪声   词汇规范化   对象标准化   2.1 移除噪声 常常将文本中的一些与结果无关的作为噪声。例如停用词、网站链接、特殊符号等等，可以做如下的python实现：   123456noise_word=[&apos;a&apos;,&apos;an&apos;,&apos;the&apos;,&apos;of&apos;,&apos;">
<meta name="keywords" content="NLP,Python,快速指南">
<meta property="og:type" content="article">
<meta property="og:title" content="Python版自然语言处理快速指南">
<meta property="og:url" content="https://chaoongithub.github.io/2018/05/27/Python版自然语言处理快速指南/index.html">
<meta property="og:site_name" content="核桃也是桃啊">
<meta property="og:description" content="1. NLP简介  标记化  把文本转化为标记的过程 标记    文本中出现的实体或词汇 文本对象 句子/短语/词汇/文章  2. 文本处理   移除噪声   词汇规范化   对象标准化   2.1 移除噪声 常常将文本中的一些与结果无关的作为噪声。例如停用词、网站链接、特殊符号等等，可以做如下的python实现：   123456noise_word=[&apos;a&apos;,&apos;an&apos;,&apos;the&apos;,&apos;of&apos;,&apos;">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-05-27T09:57:47.831Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python版自然语言处理快速指南">
<meta name="twitter:description" content="1. NLP简介  标记化  把文本转化为标记的过程 标记    文本中出现的实体或词汇 文本对象 句子/短语/词汇/文章  2. 文本处理   移除噪声   词汇规范化   对象标准化   2.1 移除噪声 常常将文本中的一些与结果无关的作为噪声。例如停用词、网站链接、特殊符号等等，可以做如下的python实现：   123456noise_word=[&apos;a&apos;,&apos;an&apos;,&apos;the&apos;,&apos;of&apos;,&apos;">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://chaoongithub.github.io/2018/05/27/Python版自然语言处理快速指南/"/>





  <title>Python版自然语言处理快速指南 | 核桃也是桃啊</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">核桃也是桃啊</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-主页">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            主页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-关于">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-标签">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-分类">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://chaoongithub.github.io/2018/05/27/Python版自然语言处理快速指南/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张海超">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="核桃也是桃啊">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Python版自然语言处理快速指南</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-27T17:56:25+08:00">
                2018-05-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/自然语言处理/" itemprop="url" rel="index">
                    <span itemprop="name">自然语言处理</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3>1. NLP简介</h3>
<ul>
<li>标记化  把文本转化为标记的过程</li>
<li>标记    文本中出现的实体或词汇</li>
<li>文本对象 句子/短语/词汇/文章</li>
</ul>
<h3>2. 文本处理</h3>
<ul>
<li>
<p>移除噪声</p>
</li>
<li>
<p>词汇规范化</p>
</li>
<li>
<p>对象标准化</p>
</li>
<li>
<p>2.1 移除噪声<br>
常常将文本中的一些与结果无关的作为噪声。例如停用词、网站链接、特殊符号等等，可以做如下的python实现：</p>
</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">noise_word=[<span class="string">'a'</span>,<span class="string">'an'</span>,<span class="string">'the'</span>,<span class="string">'of'</span>,<span class="string">'this'</span>,<span class="string">'!'</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_remove_noise</span><span class="params">(text)</span>:</span></span><br><span class="line">    words=text.split()</span><br><span class="line">    removed_words=[word <span class="keyword">for</span> word <span class="keyword">in</span> words <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> noise_word]</span><br><span class="line">    removed_words_string=<span class="string">" "</span>.join(removed_words)</span><br><span class="line">    <span class="keyword">return</span> removed_words_string</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text_remove_noise(<span class="string">"this is an apple !"</span>)</span><br></pre></td></tr></table></figure></p>
<pre><code>'is apple'
</code></pre>
<ul>
<li>2.2 词汇规范化</li>
<li>词干提取</li>
<li>词形还原</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem.wordnet <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line"><span class="keyword">from</span> nltk.stem.porter <span class="keyword">import</span> PorterStemmer</span><br><span class="line"></span><br><span class="line">lem=WordNetLemmatizer()</span><br><span class="line">stem=PorterStemmer()</span><br><span class="line"></span><br><span class="line">word1=<span class="string">"doing"</span></span><br><span class="line">lem.lemmatize(word1,<span class="string">"v"</span>)</span><br></pre></td></tr></table></figure></p>
<pre><code>u'do'
</code></pre>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">word2=<span class="string">"multiply"</span></span><br><span class="line">stem.stem(word2)</span><br></pre></td></tr></table></figure></p>
<pre><code>u'multipli'
</code></pre>
<ul>
<li>2.3 对象标准化 主要是将文本中在词典中不出现的词进行标准化</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">lookup_dict=&#123;<span class="string">'rt'</span>:<span class="string">'Retweet'</span>,<span class="string">'dm'</span>:<span class="string">'direct message'</span>,<span class="string">'awsm'</span>:<span class="string">'awesome'</span>,<span class="string">'luv'</span>:<span class="string">'love'</span>&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lookup_words</span><span class="params">(text)</span>:</span></span><br><span class="line">    words=text.split()</span><br><span class="line">    new_words=[]</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        <span class="keyword">if</span> word.lower() <span class="keyword">in</span> lookup_dict:</span><br><span class="line">            word=lookup_dict[word.lower()]</span><br><span class="line">        new_words.append(word)</span><br><span class="line">    new_text=<span class="string">" "</span>.join(new_words)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> new_text</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lookup_words(<span class="string">"RT is an awsm man"</span>)</span><br></pre></td></tr></table></figure></p>
<pre><code>'Retweet is an awesome man'
</code></pre>
<h3>3.文本到特征</h3>
<p>其实就是从文本中进行特征工程，主要包括句法分析（分词、词性标注、依存句法分析）、实体/N元模型、统计特征和词嵌入 。</p>
<ul>
<li>3.1 依存句法分析<br>
主要是以谓词为中心而构句，词与词之间的关系，用一种有向图来表示。
常用的依存句法分析，有Stanford Parser。</li>
<li>词性标注<br>
词性标注用途有消除歧义、一词多性、不同单词的特征、词性还原、更有效的移除停用词。</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> word_tokenize,pos_tag</span><br><span class="line">text=<span class="string">"I am learning Natural Language Processing on Analytics Vidhya"</span></span><br><span class="line">tokens=word_tokenize(text)</span><br><span class="line"><span class="keyword">print</span> tokens</span><br></pre></td></tr></table></figure></p>
<pre><code>['I', 'am', 'learning', 'Natural', 'Language', 'Processing', 'on', 'Analytics', 'Vidhya']
</code></pre>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> pos_tag(tokens)</span><br></pre></td></tr></table></figure></p>
<pre><code>[('I', 'PRP'), ('am', 'VBP'), ('learning', 'VBG'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('on', 'IN'), ('Analytics', 'NNP'), ('Vidhya', 'NNP')]
</code></pre>
<ul>
<li>3.2 实体提取（实体作为特征）<br>
实体主要是指句子中的名称或者动词组成一个实体词。实体识别通常要综合词典、位置标注和依存句法分析进行分析。目前主要分为主题模型和命名实体识别。</li>
<li>命名实体识别
NER通常包括三个模块：名词短语识别：根据从属关系分析和词性标注提取文本中所有的名称短语。短语分类：把提取出来的名词短语分到相应的类别。实体消除歧义：被错误分类的结果进行一层的检验，知识图谱主要包括Google知识图谱，IBM Watson和Wikipedia。</li>
<li>主题模型<br>
主题模型主要是识别文本所属的主题，会将文本中分成若干主题，主题内部的词会比较相似。目前主流的主题建模技术是潜在狄利克雷模型LDA</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LDA模型</span></span><br><span class="line"><span class="keyword">import</span> gensim </span><br><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> corpora</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">doc1 = <span class="string">"Sugar is bad to consume. My sister likes to have sugar, but not my father."</span></span><br><span class="line">doc2 = <span class="string">"My father spends a lot of time driving my sister around to dance practice."</span></span><br><span class="line">doc3 = <span class="string">"Doctors suggest that driving may cause increased stress and blood pressure."</span></span><br><span class="line"></span><br><span class="line">doc_list=[doc1,doc2,doc3]</span><br><span class="line">doc_clean=[doc.split() <span class="keyword">for</span> doc <span class="keyword">in</span> doc_list]</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立语料库词典</span></span><br><span class="line">dictionary=corpora.Dictionary(doc_clean)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建文档-词 的矩阵</span></span><br><span class="line">doc_term_matrix=[dictionary.doc2bow(doc) <span class="keyword">for</span> doc <span class="keyword">in</span> doc_clean]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用gensim构建LDA模型</span></span><br><span class="line">Lda=gensim.models.ldamodel.LdaModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练LDA模型</span></span><br><span class="line">ldamodel=Lda(doc_term_matrix,num_topics=<span class="number">3</span>,id2word=dictionary,passes=<span class="number">50</span>)</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> ldamodel.print_topics()</span><br></pre></td></tr></table></figure></p>
<pre><code>[(0, u'0.053*&quot;driving&quot; + 0.053*&quot;My&quot; + 0.053*&quot;my&quot; + 0.053*&quot;sister&quot; + 0.053*&quot;to&quot; + 0.053*&quot;practice.&quot; + 0.053*&quot;of&quot; + 0.053*&quot;a&quot; + 0.053*&quot;father&quot; + 0.053*&quot;around&quot;'), (1, u'0.029*&quot;driving&quot; + 0.029*&quot;sister&quot; + 0.029*&quot;My&quot; + 0.029*&quot;my&quot; + 0.029*&quot;to&quot; + 0.029*&quot;may&quot; + 0.029*&quot;and&quot; + 0.029*&quot;Doctors&quot; + 0.029*&quot;stress&quot; + 0.029*&quot;blood&quot;'), (2, u'0.063*&quot;to&quot; + 0.036*&quot;have&quot; + 0.036*&quot;father.&quot; + 0.036*&quot;but&quot; + 0.036*&quot;not&quot; + 0.036*&quot;consume.&quot; + 0.036*&quot;Sugar&quot; + 0.036*&quot;likes&quot; + 0.036*&quot;is&quot; + 0.036*&quot;bad&quot;')]
</code></pre>
<ul>
<li>把N元文法作为特征<br>
N元文法通常比单词包含更多信息，也是文本的重要特征</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_ngrams</span><span class="params">(text,n)</span>:</span></span><br><span class="line">    words=text.split()</span><br><span class="line">    output=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(words)-n+<span class="number">1</span>):</span><br><span class="line">        output.append(words[i:i+n])</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">generate_ngrams(<span class="string">'I am learning Natural Language Processing on Analytics Vidhya'</span>,<span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<pre><code>[['I', 'am'],
 ['am', 'learning'],
 ['learning', 'Natural'],
 ['Natural', 'Language'],
 ['Language', 'Processing'],
 ['Processing', 'on'],
 ['on', 'Analytics'],
 ['Analytics', 'Vidhya']]
</code></pre>
<ul>
<li>3.3 统计特征</li>
<li>TF-IDF</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tfidf=TfidfVectorizer()</span><br><span class="line">corpus=[<span class="string">'This is sample document.'</span>, <span class="string">'another random document.'</span>, <span class="string">'third sample document text'</span>]</span><br><span class="line">X=tfidf.fit_transform(corpus)</span><br><span class="line"><span class="keyword">print</span> X</span><br></pre></td></tr></table></figure></p>
<pre><code>  (0, 7)	0.58448290102
  (0, 2)	0.58448290102
  (0, 4)	0.444514311537
  (0, 1)	0.345205016865
  (1, 1)	0.385371627466
  (1, 0)	0.652490884513
  (1, 3)	0.652490884513
  (2, 4)	0.444514311537
  (2, 1)	0.345205016865
  (2, 6)	0.58448290102
  (2, 5)	0.58448290102
</code></pre>
<ul>
<li>3.4 词嵌入
词嵌入通常是把高维向量转化为低维向量。通常是做深度学习的基础。目前主要用的有Word2Vec和GloVe。</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line">sentences=[[<span class="string">'data'</span>, <span class="string">'science'</span>], [<span class="string">'vidhya'</span>, <span class="string">'science'</span>, <span class="string">'data'</span>, <span class="string">'analytics'</span>],[<span class="string">'machine'</span>, <span class="string">'learning'</span>], [<span class="string">'deep'</span>, <span class="string">'learning'</span>]]</span><br><span class="line"></span><br><span class="line">model=Word2Vec(sentences,min_count=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> model.similarity(<span class="string">'data'</span>,<span class="string">'science'</span>)</span><br></pre></td></tr></table></figure></p>
<pre><code>-0.236613294643
</code></pre>
<h3>4 NLP重要任务</h3>
<ul>
<li>4.1 文本分类
文本分类是NLP主要任务，主要是将文本分成不同的类别，主要包括训练分类器和预测。</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">training_corpus = [</span><br><span class="line">                   (<span class="string">'I am exhausted of this work.'</span>, <span class="string">'Class_B'</span>),</span><br><span class="line">                   (<span class="string">"I can't cooperate with this"</span>, <span class="string">'Class_B'</span>),</span><br><span class="line">                   (<span class="string">'He is my badest enemy!'</span>, <span class="string">'Class_B'</span>),</span><br><span class="line">                   (<span class="string">'My management is poor.'</span>, <span class="string">'Class_B'</span>),</span><br><span class="line">                   (<span class="string">'I love this burger.'</span>, <span class="string">'Class_A'</span>),</span><br><span class="line">                   (<span class="string">'This is an brilliant place!'</span>, <span class="string">'Class_A'</span>),</span><br><span class="line">                   (<span class="string">'I feel very good about these dates.'</span>, <span class="string">'Class_A'</span>),</span><br><span class="line">                   (<span class="string">'This is my best work.'</span>, <span class="string">'Class_A'</span>),</span><br><span class="line">                   (<span class="string">"What an awesome view"</span>, <span class="string">'Class_A'</span>),</span><br><span class="line">                   (<span class="string">'I do not like this dish'</span>, <span class="string">'Class_B'</span>)]</span><br><span class="line"></span><br><span class="line">test_corpus = [</span><br><span class="line">               (<span class="string">"I am not feeling well today."</span>, <span class="string">'Class_B'</span>),</span><br><span class="line">               (<span class="string">"I feel brilliant!"</span>, <span class="string">'Class_A'</span>),</span><br><span class="line">               (<span class="string">'Gary is a friend of mine.'</span>, <span class="string">'Class_A'</span>),</span><br><span class="line">               (<span class="string">"I can't believe I'm doing this."</span>, <span class="string">'Class_B'</span>),</span><br><span class="line">               (<span class="string">'The date was good.'</span>, <span class="string">'Class_A'</span>),</span><br><span class="line">               (<span class="string">'I do not enjoy my job'</span>, <span class="string">'Class_B'</span>)]</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"></span><br><span class="line">train_data=[]</span><br><span class="line">train_labels=[]</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> training_corpus:</span><br><span class="line">    train_data.append(row[<span class="number">0</span>])</span><br><span class="line">    train_labels.append(row[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">test_data=[]</span><br><span class="line">test_labels=[]</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> test_corpus:</span><br><span class="line">    test_data.append(row[<span class="number">0</span>])</span><br><span class="line">    test_labels.append(row[<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">vectorizer=TfidfVectorizer(min_df=<span class="number">4</span>,max_df=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">train_vectors=vectorizer.fit_transform(train_data)</span><br><span class="line"></span><br><span class="line">test_vectors=vectorizer.transform(test_data)</span><br><span class="line"></span><br><span class="line">model=svm.SVC(kernel=<span class="string">'linear'</span>)</span><br><span class="line">model.fit(train_vectors,train_labels)</span><br><span class="line">prediction=model.predict(test_vectors)</span><br><span class="line"><span class="keyword">print</span> prediction</span><br></pre></td></tr></table></figure></p>
<pre><code>['Class_A' 'Class_A' 'Class_B' 'Class_B' 'Class_A' 'Class_A']
</code></pre>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> classification_report(test_labels,prediction)</span><br></pre></td></tr></table></figure></p>
<pre><code>             precision    recall  f1-score   support

    Class_A       0.50      0.67      0.57         3
    Class_B       0.50      0.33      0.40         3

avg / total       0.50      0.50      0.49         6
</code></pre>
<ul>
<li>4.2 文本匹配度/相似度<br>
计算文本匹配度也是NLP的另一个重要任务</li>
<li>编辑距离 Levenshtein</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">levenshtein</span><span class="params">(s1,s2)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(s1) &gt; len(s2):</span><br><span class="line">        s1,s2 = s2,s1</span><br><span class="line">    distances = range(len(s1) + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> index2,char2 <span class="keyword">in</span> enumerate(s2):</span><br><span class="line">        newDistances = [index2+<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> index1,char1 <span class="keyword">in</span> enumerate(s1):</span><br><span class="line">            <span class="keyword">if</span> char1 == char2:</span><br><span class="line">                newDistances.append(distances[index1])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                newDistances.append(<span class="number">1</span> + min((distances[index1], distances[index1+<span class="number">1</span>], newDistances[<span class="number">-1</span>])))</span><br><span class="line">        distances = newDistances</span><br><span class="line">    <span class="keyword">return</span> distances[<span class="number">-1</span>]</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(levenshtein(<span class="string">"anew"</span>,<span class="string">"ans"</span>))</span><br></pre></td></tr></table></figure></p>
<pre><code>2
</code></pre>
<ul>
<li>余弦相似度</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cosine</span><span class="params">(vec1,vec2)</span>:</span></span><br><span class="line">    common=set(vec1.keys())&amp;set(vec2.keys())</span><br><span class="line">    numerator=sum([vec1[x]*vec2[x] <span class="keyword">for</span> x <span class="keyword">in</span> common])</span><br><span class="line">    </span><br><span class="line">    sum1=sum([vec1[x]**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> vec1.keys()])</span><br><span class="line">    sum2=sum([vec2[x]**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> vec2.keys()])</span><br><span class="line">    denominator=math.sqrt(sum1)*math.sqrt(sum2)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> denominator:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> float(numerator)/denominator</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_to_vector</span><span class="params">(text)</span>:</span></span><br><span class="line">    words=text.split()</span><br><span class="line">    <span class="keyword">return</span> Counter(words)</span><br><span class="line"></span><br><span class="line">text1 = <span class="string">'This is an article on analytics vidhya'</span></span><br><span class="line">text2 = <span class="string">'article on analytics vidhya is about natural language processing'</span></span><br><span class="line"></span><br><span class="line">vector1 = text_to_vector(text1)</span><br><span class="line">vector2 = text_to_vector(text2)</span><br><span class="line">cosine = cosine(vector1, vector2)</span><br><span class="line"><span class="keyword">print</span> cosine</span><br></pre></td></tr></table></figure></p>
<pre><code>0.629940788349
</code></pre>
<h3>5. NLP其他任务</h3>
<ul>
<li>文本自动摘要</li>
<li>机器翻译</li>
<li>文档自动生成</li>
<li>文本信息抽取</li>
</ul>
<h3>6. 主要的NLP库</h3>
<ul>
<li>scikit-learn</li>
<li>NLTK</li>
<li>Pattern 网页挖掘模块 可以和NLTK搭配使用</li>
<li>TextBlob 基于NLTK和Pattern架构的NLP</li>
<li>spacy 工业级的NLP库</li>
<li>gensim word2vec构建、文本抽取</li>
<li>Stanford CoreNLP</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="张海超 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="张海超 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/NLP/" rel="tag"># NLP</a>
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
            <a href="/tags/快速指南/" rel="tag"># 快速指南</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/04/21/利用LDA模型判断技术主题分布/" rel="next" title="利用LDA模型判断技术主题分布">
                <i class="fa fa-chevron-left"></i> 利用LDA模型判断技术主题分布
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNTUyMy8xMjA1OQ=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="张海超" />
            
              <p class="site-author-name" itemprop="name">张海超</p>
              <p class="site-description motion-element" itemprop="description">stay hungry, stay foolish.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/ChaoOnGithub" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/zhangmubai" target="_blank" title="微博">
                      
                        <i class="fa fa-fw fa-weibo"></i>微博</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/zhanghc-14/" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-zhihu"></i>知乎</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.github.com/" title="github" target="_blank">github</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">1.</span> <span class="nav-text">1. NLP简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">2.</span> <span class="nav-text">2. 文本处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">3.</span> <span class="nav-text">3.文本到特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">4.</span> <span class="nav-text">4 NLP重要任务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">5.</span> <span class="nav-text">5. NLP其他任务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">6.</span> <span class="nav-text">6. 主要的NLP库</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张海超</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
